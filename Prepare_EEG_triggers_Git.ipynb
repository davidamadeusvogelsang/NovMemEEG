{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script to prepare EEG triggers for the memtask of NovMemEEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code creates EEG triggers from E-prime/Excel files \n",
    "# import some libraries \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE_PATH = '/Volumes/DAVIDOVICH/NovMemEEG/EEG_triggers/'\n",
    "# DATA_PATH = '/Volumes/DAVIDOVICH/NovMemEEG/E-prime_data'\n",
    "SAVE_PATH = '/Volumes/USBC_DAV/NovMemEEG/EEG_triggers/'\n",
    "DATA_PATH = '/Volumes/DAVIDOFF/NovMemEEG/Behavioural_data_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the E=prime txt file \n",
    "def read_txt_file(file_path,run):\n",
    "    #Create an empty dictionary to store data\n",
    "    data = {}\n",
    "\n",
    "    #Open the file in read mode using utf-16 encoding\n",
    "    with open(file_path, 'r', encoding='utf-16') as f:\n",
    "        text = f.readlines()\n",
    "    #Create a generator expression that yields the index of each line that matches '\\t\\t*** LogFrame Start ***\\n'\n",
    "    if run ==0:     \n",
    "        start_ind = (i for i, _ in enumerate(text) if _ == '\\t\\t*** LogFrame Start ***\\n')\n",
    "        end_ind = (i for i, _ in enumerate(text) if _ == '\\t\\t*** LogFrame End ***\\n')\n",
    "    else:\n",
    "        start_ind = (i for i, _ in enumerate(text) if _ == '\\t*** LogFrame Start ***\\n')\n",
    "        end_ind = (i for i, _ in enumerate(text) if _ == '\\t*** LogFrame End ***\\n')\n",
    "\n",
    "    #Loop through each start-end pair and extract data between them\n",
    "    for i, se in enumerate(zip(start_ind, end_ind)):\n",
    "        s, e = se\n",
    "        for row in text[s + 1: e]:\n",
    "            k, v = row.strip().replace(': ', ':').split(':')\n",
    "            if k not in data:\n",
    "                data[k] = [[], []]\n",
    "            data[k][0].append(v)\n",
    "            data[k][1].append(i)\n",
    "    \n",
    "    new_data = {}\n",
    "    for k, v in data.items():\n",
    "        ser = pd.Series(v[0], index=v[1])\n",
    "        new_data[k] = ser\n",
    "    return pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create EEEG triggers function \n",
    "def get_triggers(df1, df2):\n",
    "    # Grab word from study phase \n",
    "    Word_idx = df1.columns.get_loc(\"Word\")\n",
    "    Word = pd.DataFrame(df1.iloc[:,Word_idx])\n",
    "\n",
    "    #Grab word from memory test \n",
    "    Wordoldew_idx = df2.columns.get_loc(\"WordOldNew\")\n",
    "    Wordoldnew = pd.DataFrame(df2.iloc[:,Wordoldew_idx])\n",
    "\n",
    "    #Grab whether oldnew in memory test was correct or not \n",
    "    OldorNewACC_idx = df2.columns.get_loc(\"OldOrNew.ACC\")\n",
    "    OldorNewACC = pd.DataFrame(df2.iloc[:,OldorNewACC_idx])\n",
    "\n",
    "    #Grab the first 60 words in the study phase \n",
    "    Word = Word.iloc[:60]\n",
    "    # add new empty columns to dataframe \n",
    "    Word[[\"EEG_event_label\",\"EEG_event_trigger\"]] = \"\"\n",
    "\n",
    "\n",
    "    for i in range(len(Word)):\n",
    "        Wordidx = Word.iloc[i][\"Word\"]\n",
    "        index = Wordoldnew.index[Wordoldnew['WordOldNew']==Wordidx].tolist()\n",
    "\n",
    "        # get the accuracy \n",
    "        acc = OldorNewACC.iloc[[index[0]]]\n",
    "        # get the value of accuracy (so 1.0 or 0.0)\n",
    "        value = acc['OldOrNew.ACC'].iloc[0]\n",
    "\n",
    "        #if value == 1.0:\n",
    "        if value == '1':\n",
    "            Word[\"EEG_event_label\"].iloc[i]  = \"novel_hit\"\n",
    "            Word[\"EEG_event_trigger\"].iloc[i]  = 6\n",
    "        #elif value == 0.0:\n",
    "        elif value == '0':\n",
    "            Word[\"EEG_event_label\"].iloc[i]  = \"novel_miss\"\n",
    "            Word[\"EEG_event_trigger\"].iloc[i]  = 5\n",
    "        else:\n",
    "            print(\"no responses given \")\n",
    "    return Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the file path for a given day and participant ID\n",
    "def get_file_path(participant_id, day):\n",
    "    folder_path = os.path.join(DATA_PATH, participant_id, day)\n",
    "    # Get a list of all the txt files in the folder that start with \"NovMem_autorecord_\" or \"NovMem2022_autorecord_\" and end with \".txt\"\n",
    "    txt_files = [f for f in os.listdir(folder_path) if (f.startswith(\"NovMem_autorecord_\") or f.startswith(\"NovMem2022_autorecord_\")) and f.endswith(\".txt\") and \"delayed\" not in f]\n",
    "    # Make sure there is only one txt file in the folder\n",
    "    assert len(txt_files) == 1, f\"Expected 1 txt file but found {len(txt_files)} in {folder_path}\"\n",
    "    return os.path.join(folder_path, txt_files[0])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all the participants and get the file paths for each day\n",
    "for participant_id in os.listdir(DATA_PATH):\n",
    "    # Ignore any files in the top-level data directory\n",
    "    if not os.path.isdir(os.path.join(DATA_PATH, participant_id)):\n",
    "        continue\n",
    "    \n",
    "    day = \"DAY2\"\n",
    "\n",
    "    # Get the file path for DAY1\n",
    "    file_path = get_file_path(participant_id, day)\n",
    "\n",
    "    run = 0\n",
    "    df1 = read_txt_file(file_path, run)\n",
    "    run = 1\n",
    "    df2 = read_txt_file(file_path, run)\n",
    "\n",
    "    EEG_triggers = get_triggers(df1,df2)\n",
    "\n",
    "    # Create the directory for the EEG triggers if it doesn't exist\n",
    "    triggers_dir = os.path.join(SAVE_PATH, participant_id, day)\n",
    "    os.makedirs(triggers_dir, exist_ok=True)\n",
    "    # Construct the file path for the excel file\n",
    "    excel_file_path = os.path.join(triggers_dir, f\"{participant_id}_{day}_MemTask_EEGtriggers.xlsx\")\n",
    "\n",
    "    # Save the dataframe with all EEG triggers to an excel file\n",
    "    EEG_triggers.to_excel(excel_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
